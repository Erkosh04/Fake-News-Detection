# app.py
import streamlit as st
import pandas as pd
import numpy as np
import os
import re
import pickle

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, f1_score, classification_report

import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

# NLTK resources
nltk.download("stopwords")
nltk.download("wordnet")
nltk.download("omw-1.4")

STOPWORDS = set(stopwords.words("english"))
LEMMATIZER = WordNetLemmatizer()

MODEL_PATH = "model.pkl"
VECTORIZER_PATH = "vectorizer.pkl"

# ---------------------------------------------------
# CLEAN TEXT
# ---------------------------------------------------
def clean_text(text):
    if not isinstance(text, str):
        return ""
    text = text.lower()
    text = re.sub(r"http\S+|www.\S+", " ", text)
    text = re.sub(r"[^a-zA-Z0-9\s]", " ", text)
    tokens = text.split()
    tokens = [t for t in tokens if t not in STOPWORDS]
    tokens = [LEMMATIZER.lemmatize(t) for t in tokens]
    return " ".join(tokens)

# ---------------------------------------------------
# FIND TEXT COLUMN
# ---------------------------------------------------
def find_text_column(df):
    for col in df.columns:
        if col.lower() in ["text", "content", "body", "article"]:
            return col
    return df.columns[0]   # fallback

# ---------------------------------------------------
# TRAIN MODEL
# ---------------------------------------------------
def train_model(df):

    # –ï–≥–µ—Ä label –∂–æ“õ –±–æ–ª—Å–∞ ‚Üí –∞–≤—Ç–æ–º–∞—Ç —Ç“Ø—Ä–¥–µ “õ–æ—Å–∞–º—ã–∑
    if "label" not in df.columns:
        st.warning("‚ö† Label –±–∞“ì–∞–Ω –∂–æ“õ ‚Üí –∞–≤—Ç–æ–º–∞—Ç —Ç“Ø—Ä–¥–µ 'label = 1' “õ–æ—Å—ã–ª–¥—ã.")
        df["label"] = 1

    text_col = find_text_column(df)
    label_col = "label"

    st.info(f"Text –±–∞“ì–∞–Ω—ã: **{text_col}**, Label –±–∞“ì–∞–Ω—ã: **{label_col}**")

    df[text_col] = df[text_col].astype(str).apply(clean_text)
    X = df[text_col].values
    y = df[label_col].values

    # Stratify fix
    unique, counts = np.unique(y, return_counts=True)
    if all(c >= 2 for c in counts):
        stratify = y
    else:
        stratify = None
        st.warning("‚ö†Ô∏è Stratify “õ–æ–ª–¥–∞–Ω—ã–ª–º–∞–π–¥—ã ‚Äî –∫–µ–π–±—ñ—Ä –∫–ª–∞—Å—Å —Ç–µ–∫ 1 –¥–∞–Ω–∞ “ì–∞–Ω–∞ –±–∞—Ä.")

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=stratify
    )

    vectorizer = TfidfVectorizer(max_features=5000)
    X_train_tf = vectorizer.fit_transform(X_train)
    X_test_tf = vectorizer.transform(X_test)

    model = LogisticRegression(max_iter=2000)
    model.fit(X_train_tf, y_train)

    preds = model.predict(X_test_tf)

    acc = accuracy_score(y_test, preds)
    f1 = f1_score(y_test, preds, average="weighted")
    rep = classification_report(y_test, preds)

    return model, vectorizer, acc, f1, rep

# ---------------------------------------------------
# STREAMLIT UI
# ---------------------------------------------------
st.title("üì∞ Fake News Detection App")

uploaded = st.file_uploader("CSV —Ñ–∞–π–ª—ã–Ω –∂“Ø–∫—Ç–µ")

if uploaded:
    df = pd.read_csv(uploaded)
    st.success(f"–§–∞–π–ª –æ“õ—ã–ª–¥—ã ‚Äî {df.shape[0]} –∂–æ–ª")

    if "label" not in df.columns:
        st.warning("‚ö† CSV —ñ—à—ñ–Ω–¥–µ label –∂–æ“õ ‚Üí –∞–≤—Ç–æ–º–∞—Ç —Ç“Ø—Ä–¥–µ 1 “õ–æ–π—ã–ª–∞–¥—ã (FAKE).")

    st.dataframe(df.head())
else:
    df = None

if st.button("–ú–æ–¥–µ–ª—å–¥—ñ “Ø–π—Ä–µ—Ç—É"):
    if df is None:
        st.error("–ê–ª–¥—ã–º–µ–Ω CSV –∂“Ø–∫—Ç–µ!")
    else:
        model, vectorizer, acc, f1, rep = train_model(df)
        st.success("–ú–æ–¥–µ–ª—å –¥–∞–π—ã–Ω!")

        st.write("üîπ **Accuracy:**", acc)
        st.write("üîπ **F1-score:**", f1)
        st.text(rep)

        # SAVE MODEL
        with open(MODEL_PATH, "wb") as f:
            pickle.dump(model, f)
        with open(VECTORIZER_PATH, "wb") as f:
            pickle.dump(vectorizer, f)
        st.info("–ú–æ–¥–µ–ª—å —Å–∞“õ—Ç–∞–ª–¥—ã!")

st.markdown("---")

st.header("–ú”ô—Ç—ñ–Ω —Ç–µ–∫—Å–µ—Ä—É")

text_input = st.text_area("–ú”ô—Ç—ñ–Ω–¥—ñ –µ–Ω–≥—ñ–∑:")

if st.button("–¢–µ–∫—Å–µ—Ä—É"):
    if not os.path.exists(MODEL_PATH):
        st.error("–ê–ª–¥—ã–º–µ–Ω –º–æ–¥–µ–ª—å–¥—ñ “Ø–π—Ä–µ—Ç!")
    else:
        with open(MODEL_PATH, "rb") as f:
            model = pickle.load(f)
        with open(VECTORIZER_PATH, "rb") as f:
            vectorizer = pickle.load(f)

        clean = clean_text(text_input)
        vect = vectorizer.transform([clean])
        pred = model.predict(vect)[0]

        label = "FAKE ‚ùå" if str(pred) in ["1", "true", "True"] else "REAL ‚úî"

        st.subheader(label)
        st.code(clean)
